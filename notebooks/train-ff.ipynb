{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7712ca-fac2-4e86-b762-13162d227dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 21:34:12.010668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a34e6f1-4b3c-4f47-8cef-adb57a068158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>e-399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-77</td>\n",
       "      <td>w-71</td>\n",
       "      <td>w-72</td>\n",
       "      <td>w-109</td>\n",
       "      <td>...</td>\n",
       "      <td>w-196</td>\n",
       "      <td>w-185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>e-399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-77</td>\n",
       "      <td>w-71</td>\n",
       "      <td>w-72</td>\n",
       "      <td>w-109</td>\n",
       "      <td>...</td>\n",
       "      <td>w-196</td>\n",
       "      <td>w-185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>e-397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-77</td>\n",
       "      <td>w-73</td>\n",
       "      <td>w-72</td>\n",
       "      <td>w-109</td>\n",
       "      <td>...</td>\n",
       "      <td>w-197</td>\n",
       "      <td>w-185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-213</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>e-396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-79</td>\n",
       "      <td>w-72</td>\n",
       "      <td>w-72</td>\n",
       "      <td>w-109</td>\n",
       "      <td>...</td>\n",
       "      <td>w-196</td>\n",
       "      <td>w-185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-213</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>e-394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-81</td>\n",
       "      <td>w-70</td>\n",
       "      <td>w-72</td>\n",
       "      <td>w-109</td>\n",
       "      <td>...</td>\n",
       "      <td>w-196</td>\n",
       "      <td>w-185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12163</th>\n",
       "      <td>-4.3</td>\n",
       "      <td>w-185</td>\n",
       "      <td>d-322</td>\n",
       "      <td>w-127</td>\n",
       "      <td>w-130</td>\n",
       "      <td>w-187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e-153</td>\n",
       "      <td>...</td>\n",
       "      <td>w-28</td>\n",
       "      <td>w-30</td>\n",
       "      <td>w-35</td>\n",
       "      <td>w-44</td>\n",
       "      <td>w-43</td>\n",
       "      <td>w-73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12164</th>\n",
       "      <td>-4.4</td>\n",
       "      <td>w-187</td>\n",
       "      <td>d-327</td>\n",
       "      <td>w-133</td>\n",
       "      <td>w-134</td>\n",
       "      <td>w-189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e-150</td>\n",
       "      <td>...</td>\n",
       "      <td>w-28</td>\n",
       "      <td>w-30</td>\n",
       "      <td>w-32</td>\n",
       "      <td>w-41</td>\n",
       "      <td>w-47</td>\n",
       "      <td>w-64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12165</th>\n",
       "      <td>-4.5</td>\n",
       "      <td>w-136</td>\n",
       "      <td>d-331</td>\n",
       "      <td>w-144</td>\n",
       "      <td>w-137</td>\n",
       "      <td>w-191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e-148</td>\n",
       "      <td>...</td>\n",
       "      <td>w-31</td>\n",
       "      <td>w-29</td>\n",
       "      <td>w-33</td>\n",
       "      <td>w-40</td>\n",
       "      <td>w-51</td>\n",
       "      <td>w-56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12166</th>\n",
       "      <td>-4.6</td>\n",
       "      <td>w-96</td>\n",
       "      <td>d-336</td>\n",
       "      <td>w-152</td>\n",
       "      <td>w-137</td>\n",
       "      <td>w-193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e-145</td>\n",
       "      <td>...</td>\n",
       "      <td>w-35</td>\n",
       "      <td>w-32</td>\n",
       "      <td>w-31</td>\n",
       "      <td>w-37</td>\n",
       "      <td>w-53</td>\n",
       "      <td>w-59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>-4.7</td>\n",
       "      <td>w-94</td>\n",
       "      <td>d-340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w-139</td>\n",
       "      <td>w-195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e-143</td>\n",
       "      <td>...</td>\n",
       "      <td>w-35</td>\n",
       "      <td>w-33</td>\n",
       "      <td>w-31</td>\n",
       "      <td>w-38</td>\n",
       "      <td>w-50</td>\n",
       "      <td>w-59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12168 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5     6     7     8      9   ...  \\\n",
       "0      0.1  e-399    NaN  w-219    NaN    NaN  w-77  w-71  w-72  w-109  ...   \n",
       "1      0.3  e-399    NaN  w-219    NaN    NaN  w-77  w-71  w-72  w-109  ...   \n",
       "2      0.6  e-397    NaN  w-215    NaN    NaN  w-77  w-73  w-72  w-109  ...   \n",
       "3      0.8  e-396    NaN  w-214    NaN    NaN  w-79  w-72  w-72  w-109  ...   \n",
       "4      1.0  e-394    NaN  w-211    NaN    NaN  w-81  w-70  w-72  w-109  ...   \n",
       "...    ...    ...    ...    ...    ...    ...   ...   ...   ...    ...  ...   \n",
       "12163 -4.3  w-185  d-322  w-127  w-130  w-187   NaN   NaN   NaN  e-153  ...   \n",
       "12164 -4.4  w-187  d-327  w-133  w-134  w-189   NaN   NaN   NaN  e-150  ...   \n",
       "12165 -4.5  w-136  d-331  w-144  w-137  w-191   NaN   NaN   NaN  e-148  ...   \n",
       "12166 -4.6   w-96  d-336  w-152  w-137  w-193   NaN   NaN   NaN  e-145  ...   \n",
       "12167 -4.7   w-94  d-340    NaN  w-139  w-195   NaN   NaN   NaN  e-143  ...   \n",
       "\n",
       "          19     20    21    22    23     24 25 26 27 28  \n",
       "0      w-196  w-185   NaN   NaN   NaN  w-215  1  0  0  0  \n",
       "1      w-196  w-185   NaN   NaN   NaN  w-215  1  0  0  0  \n",
       "2      w-197  w-185   NaN   NaN   NaN  w-213  1  0  0  0  \n",
       "3      w-196  w-185   NaN   NaN   NaN  w-213  1  0  0  0  \n",
       "4      w-196  w-185   NaN   NaN   NaN  w-211  1  0  0  0  \n",
       "...      ...    ...   ...   ...   ...    ... .. .. .. ..  \n",
       "12163   w-28   w-30  w-35  w-44  w-43   w-73  0  1  1  0  \n",
       "12164   w-28   w-30  w-32  w-41  w-47   w-64  0  1  1  0  \n",
       "12165   w-31   w-29  w-33  w-40  w-51   w-56  0  1  1  0  \n",
       "12166   w-35   w-32  w-31  w-37  w-53   w-59  0  1  1  0  \n",
       "12167   w-35   w-33  w-31  w-38  w-50   w-59  0  1  1  0  \n",
       "\n",
       "[12168 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\", header=None)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd71c54-97e9-42e2-b757-00bc87b82bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[0], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91abfc3b-424c-4433-be77-edc8c3648898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(1, 0, 0, 0): 1826,\n",
       "         (1, 0, 1, 0): 869,\n",
       "         (0, 0, 1, 0): 2871,\n",
       "         (0, 0, 0, 0): 2585,\n",
       "         (0, 1, 0, 0): 353,\n",
       "         (0, 0, 0, 1): 2689,\n",
       "         (1, 0, 0, 1): 651,\n",
       "         (0, 1, 1, 0): 196,\n",
       "         (0, 1, 0, 1): 127,\n",
       "         (0, 0, 1, 1): 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tuple(row[1]) for row in data[[25,26,27,28]].iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9e60f7-89c1-4a18-876c-fcdd2dbfb7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d98d058d9d64c37a110429130d1feab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((12168, 49), (12168, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_sensor(s, letters, max_val=501.0):\n",
    "    if not s:\n",
    "        return 1.0\n",
    "    if s[0] not in letters:\n",
    "        return 1.0\n",
    "    return float(s[2:])/max_val\n",
    "    \n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "with open(\"train.csv\") as f:\n",
    "    for row in tqdm(csv.reader(f)):\n",
    "        velocity = np.array([float(row[0])])\n",
    "        sensors = row[1:25]\n",
    "        keys = np.fromiter((float(k) for k in row[25:]), dtype=float)\n",
    "        walls = np.fromiter((parse_sensor(s, (\"w\", \"e\")) for s in sensors), dtype=float)\n",
    "        diamants = np.fromiter((parse_sensor(s, (\"d\")) for s in sensors), dtype=float)\n",
    "        X.append(np.concatenate((velocity, walls, diamants)))\n",
    "        Y.append(keys)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bae7924-8970-424b-bae2-a23cf39b3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ff_model():\n",
    "    tf.random.set_seed(42)\n",
    "    input = tf.keras.Input(shape=(49,), name=\"input\")\n",
    "    hidden = tf.keras.layers.Dense(64, activation=\"tanh\", name=\"hidden1\")(input)\n",
    "    output = tf.keras.layers.Dense(4, activation='sigmoid', name='output')(hidden)\n",
    "\n",
    "    model = tf.keras.Model(name=\"ff_model\", inputs=input, outputs=output)\n",
    "    model.compile(optimizer='adam', loss=\"binary_crossentropy\")\n",
    "    return model\n",
    "\n",
    "ff_model = create_ff_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02547e4-fe45-41c6-acc5-e78b2d9c7861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ff_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ff_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,460</span> (13.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,460\u001b[0m (13.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,460</span> (13.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,460\u001b[0m (13.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ff_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1db0e7d3-c083-4fe9-bc5a-d87be139f02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4874 - val_loss: 0.4336\n",
      "Epoch 2/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.4030 - val_loss: 0.4241\n",
      "Epoch 3/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.3903 - val_loss: 0.4208\n",
      "Epoch 4/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.3846 - val_loss: 0.4185\n",
      "Epoch 5/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.3807 - val_loss: 0.4166\n",
      "Epoch 6/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.3774 - val_loss: 0.4150\n",
      "Epoch 7/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.3744 - val_loss: 0.4135\n",
      "Epoch 8/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.3715 - val_loss: 0.4120\n",
      "Epoch 9/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.3689 - val_loss: 0.4107\n",
      "Epoch 10/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.3663 - val_loss: 0.4093\n",
      "Epoch 11/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.3638 - val_loss: 0.4080\n",
      "Epoch 12/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.3614 - val_loss: 0.4068\n",
      "Epoch 13/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.3591 - val_loss: 0.4057\n",
      "Epoch 14/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.3568 - val_loss: 0.4046\n",
      "Epoch 15/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.3545 - val_loss: 0.4036\n",
      "Epoch 16/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.3523 - val_loss: 0.4028\n",
      "Epoch 17/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.3501 - val_loss: 0.4020\n",
      "Epoch 18/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.3480 - val_loss: 0.4012\n",
      "Epoch 19/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.3460 - val_loss: 0.4006\n",
      "Epoch 20/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.3440 - val_loss: 0.4000\n",
      "Epoch 21/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.3420 - val_loss: 0.3995\n",
      "Epoch 22/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.3400 - val_loss: 0.3990\n",
      "Epoch 23/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.3381 - val_loss: 0.3986\n",
      "Epoch 24/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.3362 - val_loss: 0.3983\n",
      "Epoch 25/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.3344 - val_loss: 0.3980\n",
      "Epoch 26/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.3325 - val_loss: 0.3978\n",
      "Epoch 27/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.3307 - val_loss: 0.3977\n",
      "Epoch 28/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.3289 - val_loss: 0.3976\n",
      "Epoch 29/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.3272 - val_loss: 0.3977\n",
      "Epoch 30/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.3254 - val_loss: 0.3978\n",
      "Epoch 31/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.3237 - val_loss: 0.3979\n",
      "Epoch 32/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.3220 - val_loss: 0.3982\n",
      "Epoch 33/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.3204 - val_loss: 0.3984\n",
      "Epoch 34/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.3187 - val_loss: 0.3988\n",
      "Epoch 35/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.3171 - val_loss: 0.3992\n",
      "Epoch 36/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.3155 - val_loss: 0.3997\n",
      "Epoch 37/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.3139 - val_loss: 0.4003\n",
      "Epoch 38/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.3123 - val_loss: 0.4010\n",
      "Epoch 39/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.3107 - val_loss: 0.4017\n",
      "Epoch 40/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.3092 - val_loss: 0.4024\n",
      "Epoch 41/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.3077 - val_loss: 0.4031\n",
      "Epoch 42/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.3062 - val_loss: 0.4038\n",
      "Epoch 43/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.3047 - val_loss: 0.4045\n",
      "Epoch 44/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.3033 - val_loss: 0.4053\n",
      "Epoch 45/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 0.3018 - val_loss: 0.4061\n",
      "Epoch 46/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.3004 - val_loss: 0.4069\n",
      "Epoch 47/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.2990 - val_loss: 0.4078\n",
      "Epoch 48/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.2977 - val_loss: 0.4087\n",
      "Epoch 49/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.2963 - val_loss: 0.4096\n",
      "Epoch 50/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.2949 - val_loss: 0.4106\n",
      "Epoch 51/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.2935 - val_loss: 0.4115\n",
      "Epoch 52/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.2921 - val_loss: 0.4125\n",
      "Epoch 53/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.2908 - val_loss: 0.4135\n",
      "Epoch 54/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.2895 - val_loss: 0.4146\n",
      "Epoch 55/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.2882 - val_loss: 0.4156\n",
      "Epoch 56/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.2869 - val_loss: 0.4167\n",
      "Epoch 57/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.2856 - val_loss: 0.4178\n",
      "Epoch 58/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.2843 - val_loss: 0.4189\n",
      "Epoch 59/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.2831 - val_loss: 0.4201\n",
      "Epoch 60/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.2818 - val_loss: 0.4212\n",
      "Epoch 61/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.2806 - val_loss: 0.4224\n",
      "Epoch 62/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.2794 - val_loss: 0.4236\n",
      "Epoch 63/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.2781 - val_loss: 0.4248\n",
      "Epoch 64/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.2769 - val_loss: 0.4260\n",
      "Epoch 65/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.2757 - val_loss: 0.4272\n",
      "Epoch 66/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.2745 - val_loss: 0.4284\n",
      "Epoch 67/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.2734 - val_loss: 0.4297\n",
      "Epoch 68/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.2722 - val_loss: 0.4309\n",
      "Epoch 69/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.2710 - val_loss: 0.4322\n",
      "Epoch 70/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.2699 - val_loss: 0.4334\n",
      "Epoch 71/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.2688 - val_loss: 0.4347\n",
      "Epoch 72/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.2676 - val_loss: 0.4360\n",
      "Epoch 73/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.2665 - val_loss: 0.4373\n",
      "Epoch 74/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.2654 - val_loss: 0.4386\n",
      "Epoch 75/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.2643 - val_loss: 0.4398\n",
      "Epoch 76/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.2632 - val_loss: 0.4412\n",
      "Epoch 77/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.2622 - val_loss: 0.4425\n",
      "Epoch 78/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.2611 - val_loss: 0.4438\n",
      "Epoch 79/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.2600 - val_loss: 0.4451\n",
      "Epoch 80/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.2590 - val_loss: 0.4464\n",
      "Epoch 81/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.2579 - val_loss: 0.4478\n",
      "Epoch 82/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.2569 - val_loss: 0.4491\n",
      "Epoch 83/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.2559 - val_loss: 0.4504\n",
      "Epoch 84/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.2549 - val_loss: 0.4518\n",
      "Epoch 85/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.2539 - val_loss: 0.4531\n",
      "Epoch 86/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.2529 - val_loss: 0.4545\n",
      "Epoch 87/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.2519 - val_loss: 0.4558\n",
      "Epoch 88/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.2509 - val_loss: 0.4572\n",
      "Epoch 89/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.2500 - val_loss: 0.4586\n",
      "Epoch 90/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.2490 - val_loss: 0.4599\n",
      "Epoch 91/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.2481 - val_loss: 0.4613\n",
      "Epoch 92/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.2471 - val_loss: 0.4627\n",
      "Epoch 93/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.2462 - val_loss: 0.4640\n",
      "Epoch 94/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.2453 - val_loss: 0.4655\n",
      "Epoch 95/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.2444 - val_loss: 0.4677\n",
      "Epoch 96/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.2434 - val_loss: 0.4688\n",
      "Epoch 97/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.2425 - val_loss: 0.4700\n",
      "Epoch 98/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.2416 - val_loss: 0.4713\n",
      "Epoch 99/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.2407 - val_loss: 0.4725\n",
      "Epoch 100/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.2399 - val_loss: 0.4738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78d9dda1b990>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "ff_model.fit(X, Y, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d44a878a-b236-43f4-b43e-d441b5a9c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ff/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ff/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../models/ff'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 49), dtype=tf.float32, name='input')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  132877121489728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877121490960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877121490784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  132877121490080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "ff_model.export(\"../models/ff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ce7be2a-348d-47bf-9fb7-d36a4d8e71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "test_input = np.array([[random.random() for _ in range(49)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a38792c9-bc14-445f-9637-7b40008c282e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.6087681e-04, 7.4695092e-01, 7.2963857e-03, 9.4691783e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_model(test_input)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b14d7c9e-8f0a-4b59-8cb0-d9e2a9ea7a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "2024-06-08 21:49:41,153 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-06-08 21:49:41,154 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2024-06-08 21:49:41,278 - INFO - Signatures found in model: [serve,serving_default].\n",
      "2024-06-08 21:49:41,278 - WARNING - '--signature_def' not specified, using first signature: serve\n",
      "2024-06-08 21:49:41,278 - INFO - Output names: ['output_0']\n",
      "2024-06-08 21:49:41,357 - INFO - Using tensorflow=2.16.1, onnx=1.16.1, tf2onnx=1.16.1/15c810\n",
      "2024-06-08 21:49:41,357 - INFO - Using opset <onnx, 13>\n",
      "2024-06-08 21:49:41,363 - INFO - Computed 0 values for constant folding\n",
      "2024-06-08 21:49:41,371 - INFO - Optimizing ONNX model\n",
      "2024-06-08 21:49:41,399 - INFO - After optimization: Identity -2 (2->0)\n",
      "2024-06-08 21:49:41,400 - INFO - \n",
      "2024-06-08 21:49:41,400 - INFO - Successfully converted TensorFlow model ../models/ff to ONNX\n",
      "2024-06-08 21:49:41,401 - INFO - Model inputs: ['input']\n",
      "2024-06-08 21:49:41,401 - INFO - Model outputs: ['output_0']\n",
      "2024-06-08 21:49:41,401 - INFO - ONNX model is saved at ../models/ff.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --saved-model ../models/ff --output ../models/ff.onnx --opset 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5846b97f-b0bc-407d-af9a-bb976afc7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9830f42-3807-457d-9c4e-871217e81f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_session = onnxruntime.InferenceSession(\"../models/ff.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af4e7b7b-ba38-4f8d-8111-e27147ebc110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.6089969e-04, 7.4695057e-01, 7.2963834e-03, 9.4691777e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_session.run([\"output_0\"], {\"input\": test_input.astype(np.float32)})[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "038f2da9-bb79-4a8b-8f28-abd368c5d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1 + np.exp(-x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "661cf3fd-00f3-4af2-9e22-3f212185812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_numpy_model(tf_model):\n",
    "    weights = [w.numpy().astype(np.float32) for w in tf_model.weights]\n",
    "\n",
    "    def numpy_model(input):\n",
    "        hidden = np.tanh(np.matmul(input, weights[0]) + weights[1])\n",
    "        output = sigmoid(np.matmul(hidden, weights[2]) + weights[3])\n",
    "        return output\n",
    "\n",
    "    return numpy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e78f5eb4-7518-40d2-b63c-d2b7778d386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_model_np = create_numpy_model(ff_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "65d4352f-f62a-4e21-9541-6055d9b8ff2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.6087571e-04, 7.4695092e-01, 7.2963797e-03, 9.4691777e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_model_np(test_input.astype(np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
